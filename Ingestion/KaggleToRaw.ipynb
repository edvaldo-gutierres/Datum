{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ac27f524-9a5f-4ea8-996c-665fd3307802",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Define os parâmetros da Job\n",
    "dbutils.widgets.text('p_path','')\n",
    "dbutils.widgets.text('p_dataset_name','')\n",
    "dbutils.widgets.text('p_path_layer_name','')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "71ff33e2-b7d0-448b-96ba-6e777ff5047c",
     "showTitle": true,
     "title": "Lê arquivo"
    }
   },
   "source": [
    "### Lê arquivo kaggle.json com as credenciais de acesso à API e cria variavies de conexão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "aea944b1-c942-4add-a929-94e5f4e81371",
     "showTitle": true,
     "title": "Copia arquivo kaggle.json para ambiente local"
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dbutils.fs.cp(\"dbfs:/FileStore/kaggle.json\", \"file:/root/.kaggle/kaggle.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c0ca1d16-981f-425f-8778-8f3b810b9f74",
     "showTitle": true,
     "title": "Importa bibliotecas"
    }
   },
   "outputs": [],
   "source": [
    "# Importa bibliotecas\n",
    "from kaggle.api.kaggle_api_extended import KaggleApi    # Lib já instalada no cluster\n",
    "from shutil import rmtree\n",
    "import os\n",
    "import json\n",
    "import tempfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ca3f249d-5c9d-45b3-96df-cf12c8928556",
     "showTitle": true,
     "title": "Busca credenciais de Conexão"
    }
   },
   "outputs": [],
   "source": [
    "def read_kaggle_credentials(file_path_json: str) -> tuple:\n",
    "    \"\"\"\n",
    "    Lê as credenciais do Kaggle de um arquivo JSON armazenado no caminho especificado.\n",
    "\n",
    "    Parâmetros:\n",
    "    file_path (str): Caminho completo até o arquivo JSON.\n",
    "\n",
    "    Retorna:\n",
    "    tuple: Contém o nome de usuário e a chave do Kaggle, e um booleano indicando se ambas as credenciais são não nulas.\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        # Lê o arquivo JSON\n",
    "        with open(file_path_json, 'r') as file:\n",
    "            credentials = json.load(file)\n",
    "        \n",
    "        # Extrai as credenciais\n",
    "        KAGGLE_USERNAME = credentials['username']\n",
    "        KAGGLE_KEY = credentials['key']\n",
    "        \n",
    "        # Verifica se ambas as credenciais são não nulas\n",
    "        credentials_found = bool(KAGGLE_USERNAME and KAGGLE_KEY)\n",
    "        return (KAGGLE_USERNAME, KAGGLE_KEY, credentials_found)\n",
    "    except Exception as e:\n",
    "        print(f\"Erro ao ler as credenciais: {e}\")\n",
    "        return (None, None, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8956daef-6765-41c3-9cbc-46e6e7940df8",
     "showTitle": true,
     "title": "Cria função para verificar conexão com a API"
    }
   },
   "outputs": [],
   "source": [
    "def autentifica_kaggle(KAGGLE_USERNAME :str, KAGGLE_KEY :str) -> KaggleApi:\n",
    "    \"\"\"\n",
    "    Autentica na API do Kaggle utilizando as credenciais fornecidas.\n",
    "\n",
    "    Parâmetros:\n",
    "    KAGGLE_USERNAME (str): Nome de usuário do Kaggle.\n",
    "    KAGGLE_KEY (str): Chave de API do Kaggle.\n",
    "\n",
    "    Retorna:\n",
    "    KaggleApi: Instância da API do Kaggle autenticada.\n",
    "    \"\"\"\n",
    "\n",
    "    # Define as variavéis de ambiente\n",
    "    os.environ['KAGGLE_USERNAME'] = KAGGLE_USERNAME\n",
    "    os.environ['KAGGLE_KEY'] = KAGGLE_KEY\n",
    "\n",
    "    # Cria e autentica uma instância da API do Kaggle\n",
    "    api = KaggleApi()\n",
    "    api.authenticate()\n",
    "\n",
    "    print('Conexão estabelecida com sucesso!')\n",
    "\n",
    "    return api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "30b5a31a-8e0c-4f2e-89c5-33afda756c6c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def download_kaggle_dataset_adsl(dataset_name, path_adsl, KAGGLE_USERNAME: str, KAGGLE_KEY: str)->None:\n",
    "    \"\"\"\n",
    "    Baixa e extrai um dataset do Kaggle e salva no Azure Data Lake Storage.\n",
    "\n",
    "    Parâmetros:\n",
    "    dataset_name (str): Nome do dataset no Kaggle.\n",
    "    path_adsl (str): Caminho no Azure Data Lake Storage onde o dataset será salvo.\n",
    "    KAGGLE_USERNAME (str): Nome de usuário do Kaggle.\n",
    "    KAGGLE_KEY (str): Chave de API do Kaggle.\n",
    "    \"\"\"\n",
    "\n",
    "    # Tentativa de Autentificação\n",
    "    try:\n",
    "        api = autentifica_kaggle(KAGGLE_USERNAME, KAGGLE_KEY)\n",
    "    except Exception as e :\n",
    "        print(f\"Erro de autenticação: {e}\")\n",
    "        print('Verifique se as credenciais estão corretas e se a biblioteca kaggle está instalada')\n",
    "        return  # Encerra a função se a autenticação falhar\n",
    "    \n",
    "    # Tentativa de download e extração do dataset\n",
    "    try:\n",
    "        with tempfile.TemporaryDirectory() as tmpdir:\n",
    "            api.dataset_download_files(dataset_name, path=tmpdir, unzip=True)                   # Tentativa de download e extração do dataset\n",
    "\n",
    "            arquivos = os.listdir(tmpdir)\n",
    "            for arquivo in arquivos:\n",
    "                file_path = os.path.join(tmpdir, arquivo)\n",
    "                path_destination_adsl = os.path.join(path_adsl, arquivo)\n",
    "                dbutils.fs.cp(f\"file:{file_path}\", path_destination_adsl)\n",
    "                print(f\"* Arquivo {arquivo} salvo em {path_destination_adsl}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Erro ao baixar o dataset: {e}\")\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7021a032-18ae-47bc-b32c-c07ea95b7596",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def download_kaggle_dataset_dbfs(dataset_name, path_dbfs, KAGGLE_USERNAME: str, KAGGLE_KEY: str)->None:\n",
    "    \"\"\"\n",
    "    Baixa e extrai um dataset do Kaggle e salva no Azure Data Lake Storage.\n",
    "\n",
    "    Parâmetros:\n",
    "    dataset_name (str): Nome do dataset no Kaggle.\n",
    "    path_adsl (str): Caminho no Azure Data Lake Storage onde o dataset será salvo.\n",
    "    KAGGLE_USERNAME (str): Nome de usuário do Kaggle.\n",
    "    KAGGLE_KEY (str): Chave de API do Kaggle.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Tentativa de Autentificação\n",
    "    try:\n",
    "        api = autentifica_kaggle(KAGGLE_USERNAME, KAGGLE_KEY)\n",
    "    except Exception as e :\n",
    "        print(f\"Erro de autenticação: {e}\")\n",
    "        print('Verifique se as credenciais estão corretas e se a biblioteca kaggle está instalada')\n",
    "        return  # Encerra a função se a autenticação falhar\n",
    "    \n",
    "    # Tentativa de download e extração do dataset\n",
    "    try:\n",
    "        with tempfile.TemporaryDirectory() as tmpdir:\n",
    "            api.dataset_download_files(dataset_name, path=tmpdir, unzip=True)                   # Tentativa de download e extração do dataset\n",
    "\n",
    "            arquivos = os.listdir(tmpdir)\n",
    "            for arquivo in arquivos:\n",
    "                file_path = os.path.join(tmpdir, arquivo)\n",
    "                path_destination_dbfs = os.path.join(path_dbfs, arquivo)\n",
    "                dbutils.fs.cp(f\"file:{file_path}\", path_destination_dbfs)\n",
    "                print(f\"* Arquivo {arquivo} salvo em {path_destination_dbfs}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Erro ao baixar o dataset: {e}\")\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8475abfa-9ade-4525-8ad9-2bd41eee4ee9",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Função principal que orquestra a execução das funções acima\n",
    "def main():\n",
    "    # Define os valores para os parâmetros (Valores passados na Job)\n",
    "\n",
    "    # path = 'abfss://datum-metastore@proofconceptdatum.dfs.core.windows.net'\n",
    "    # path_layer_name = 'raw'\n",
    "    # file_name_json = 'kaggle.json'\n",
    "    # dataset_name = 'marian447/retail-store-sales-transactions'\n",
    "\n",
    "    path = dbutils.widgets.get('p_path')\n",
    "    path_layer_name = dbutils.widgets.get('p_path_layer_name')\n",
    "    dataset_name = dbutils.widgets.get('p_dataset_name')\n",
    "\n",
    "    path_adsl = f'{path}/{path_layer_name}/'\n",
    "    path_dbfs = f'{path}/{path_layer_name}/'\n",
    "    file_path_json = '/root/.kaggle/kaggle.json'\n",
    "\n",
    "    # Recupera as credencias executando a função read_kaggle_credentials\n",
    "    credentials = read_kaggle_credentials(file_path_json=file_path_json)\n",
    "    user = credentials[0]\n",
    "    key = credentials[1]\n",
    "\n",
    "    # Faz o download, extrai o dataset e salva na pasta especificada executando a função download_kaggle_dataset\n",
    "    # download_kaggle_dataset_adsl(dataset_name=dataset_name, path_adsl=path_adsl, KAGGLE_USERNAME=user, KAGGLE_KEY=key)\n",
    "    download_kaggle_dataset_dbfs(dataset_name=dataset_name, path_dbfs=path_dbfs, KAGGLE_USERNAME=user, KAGGLE_KEY=key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e6ebb8ca-bec5-44c8-9403-3686c06a672b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n",
       "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)\n",
       "File \u001B[0;32m<command-508162604964217>, line 3\u001B[0m\n",
       "\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# Bloco que verifica se o script é o ponto de entrada principal\u001B[39;00m\n",
       "\u001B[1;32m      2\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;18m__name__\u001B[39m \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m__main__\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n",
       "\u001B[0;32m----> 3\u001B[0m     \u001B[43mmain\u001B[49m()\n",
       "\n",
       "\u001B[0;31mNameError\u001B[0m: name 'main' is not defined"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)\nFile \u001B[0;32m<command-508162604964217>, line 3\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# Bloco que verifica se o script é o ponto de entrada principal\u001B[39;00m\n\u001B[1;32m      2\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;18m__name__\u001B[39m \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m__main__\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[0;32m----> 3\u001B[0m     \u001B[43mmain\u001B[49m()\n\n\u001B[0;31mNameError\u001B[0m: name 'main' is not defined",
       "errorSummary": "<span class='ansi-red-fg'>NameError</span>: name 'main' is not defined",
       "errorTraceType": "ansi",
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Bloco que verifica se o script é o ponto de entrada principal\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "19530143-762f-4efc-bc72-60b91db20ab9",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### _A função criada \"download_kaggle_dataset_adsl\" foi mais pra exemplificar como trabalhar com serviço em cloud. Devido a quantidade baixa de dados, vamos optar por trabalhar com os arquivos no DBFS_"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": -1,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "KaggleToRaw",
   "widgets": {
    "p_dataset_name": {
     "currentValue": "olistbr/brazilian-ecommerce",
     "nuid": "07c4168e-0f0d-42fe-a244-d3fb89479fc8",
     "typedWidgetInfo": null,
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "",
      "label": null,
      "name": "p_dataset_name",
      "options": {
       "widgetType": "text",
       "autoCreated": null,
       "validationRegex": null
      }
     }
    },
    "p_path": {
     "currentValue": "dbfs:/FileStore/datum/",
     "nuid": "3a5a0fdd-c65a-4a88-8e6b-eef0ce5a9341",
     "typedWidgetInfo": null,
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "",
      "label": null,
      "name": "p_path",
      "options": {
       "widgetType": "text",
       "autoCreated": null,
       "validationRegex": null
      }
     }
    },
    "p_path_layer_name": {
     "currentValue": "raw/olistbr-brazilian-ecommerce",
     "nuid": "da829f6e-4de6-40d4-97e6-d118fcc5685e",
     "typedWidgetInfo": null,
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "",
      "label": null,
      "name": "p_path_layer_name",
      "options": {
       "widgetType": "text",
       "autoCreated": null,
       "validationRegex": null
      }
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
